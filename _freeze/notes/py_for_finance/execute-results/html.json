{
  "hash": "28a53164cd3f1c47157d20ab9a1d0859",
  "result": {
    "markdown": "---\ndate: \"2023-05-10\"\ndate-modified: \"2023-05-19\"\ntoc: true\ntitle: LinkedIn course - Financial data analysis notes\ndescription: Notes on data analysis on finance data\n---\n\nFor financial data analysis, it is important to know certain terminologies, their purpose,\nand how to calculate them. \n\nI'm taking [Matt Harrison](https://twitter.com/__mharrison__)'s Linkedin course on [Python\nfor Finance](https://www.linkedin.com/learning/getting-started-with-python-for-finance).\nHere I note down all the Pandas techniques and concepts explored in the course. As always if you find an error,\ndon't hesitate to contact me.\n\n# Loading data\n\nWe use the `yfinance` library to load our stock data. The stocks listed in NASDAQ stock\nexchange are identified using a unique symbol aka **ticker** . I was interested in seeing how\nPfizer(PFE) stocks fair in the last 3 years.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\npharma_df = yf.download('PFE JNJ', start='2015-01-01', end='2023-04-28')\npharma_df.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[                       0%                       ]\r[*********************100%***********************]  2 of 2 completed\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">Adj Close</th>\n      <th colspan=\"2\" halign=\"left\">Close</th>\n      <th colspan=\"2\" halign=\"left\">High</th>\n      <th colspan=\"2\" halign=\"left\">Low</th>\n      <th colspan=\"2\" halign=\"left\">Open</th>\n      <th colspan=\"2\" halign=\"left\">Volume</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>JNJ</th>\n      <th>PFE</th>\n      <th>JNJ</th>\n      <th>PFE</th>\n      <th>JNJ</th>\n      <th>PFE</th>\n      <th>JNJ</th>\n      <th>PFE</th>\n      <th>JNJ</th>\n      <th>PFE</th>\n      <th>JNJ</th>\n      <th>PFE</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>83.703026</td>\n      <td>21.793072</td>\n      <td>104.519997</td>\n      <td>29.724857</td>\n      <td>105.550003</td>\n      <td>30.151802</td>\n      <td>104.129997</td>\n      <td>29.620493</td>\n      <td>105.050003</td>\n      <td>29.667933</td>\n      <td>5753600</td>\n      <td>16371571</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>83.118408</td>\n      <td>21.674822</td>\n      <td>103.790001</td>\n      <td>29.563566</td>\n      <td>104.730003</td>\n      <td>29.800758</td>\n      <td>103.680000</td>\n      <td>29.421251</td>\n      <td>104.480003</td>\n      <td>29.743834</td>\n      <td>8079300</td>\n      <td>24786391</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>82.709999</td>\n      <td>21.855675</td>\n      <td>103.279999</td>\n      <td>29.810247</td>\n      <td>104.989998</td>\n      <td>30.227703</td>\n      <td>102.940002</td>\n      <td>29.525618</td>\n      <td>104.339996</td>\n      <td>29.667933</td>\n      <td>7428000</td>\n      <td>29468681</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>84.535889</td>\n      <td>22.154793</td>\n      <td>105.559998</td>\n      <td>30.218216</td>\n      <td>105.830002</td>\n      <td>30.237192</td>\n      <td>103.809998</td>\n      <td>29.962049</td>\n      <td>103.910004</td>\n      <td>30.094877</td>\n      <td>7931700</td>\n      <td>20248816</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>85.200562</td>\n      <td>22.606922</td>\n      <td>106.389999</td>\n      <td>30.834915</td>\n      <td>106.489998</td>\n      <td>30.967743</td>\n      <td>105.750000</td>\n      <td>30.569260</td>\n      <td>106.059998</td>\n      <td>30.683111</td>\n      <td>9916000</td>\n      <td>49169522</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Chaining\n\nMatt introduces one of the features in Pandas called **chaining**. It allows reading the\ncode as a recipe. One can simply go through from top to bottom and understand how the code\nworks. We leverage `pipe()` pandas function. We can use it call any function. \n\nFrom the two stocks, `PFE` and `JNJ`, we need only `PFE`. So, we can try to use chaining\nprinciple. \n\n### Without chaining\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef fix_cols(df):\n    cols = df.columns\n    outer = [col[0] for col in cols]\n    df.columns = outer\n    return df\n\npfe_df1 = pharma_df.iloc[:,1::2]\npfe_df1 = fix_cols(pfe_df1)\npfe_df1\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adj Close</th>\n      <th>Close</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>21.793072</td>\n      <td>29.724857</td>\n      <td>30.151802</td>\n      <td>29.620493</td>\n      <td>29.667933</td>\n      <td>16371571</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>21.674822</td>\n      <td>29.563566</td>\n      <td>29.800758</td>\n      <td>29.421251</td>\n      <td>29.743834</td>\n      <td>24786391</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>21.855675</td>\n      <td>29.810247</td>\n      <td>30.227703</td>\n      <td>29.525618</td>\n      <td>29.667933</td>\n      <td>29468681</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>22.154793</td>\n      <td>30.218216</td>\n      <td>30.237192</td>\n      <td>29.962049</td>\n      <td>30.094877</td>\n      <td>20248816</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>22.606922</td>\n      <td>30.834915</td>\n      <td>30.967743</td>\n      <td>30.569260</td>\n      <td>30.683111</td>\n      <td>49169522</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-21</th>\n      <td>39.779552</td>\n      <td>40.209999</td>\n      <td>40.299999</td>\n      <td>39.910000</td>\n      <td>40.090000</td>\n      <td>19227100</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>39.482765</td>\n      <td>39.910000</td>\n      <td>40.200001</td>\n      <td>39.709999</td>\n      <td>40.189999</td>\n      <td>17633700</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>38.908978</td>\n      <td>39.330002</td>\n      <td>39.919998</td>\n      <td>39.279999</td>\n      <td>39.750000</td>\n      <td>24492400</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>38.216469</td>\n      <td>38.630001</td>\n      <td>39.189999</td>\n      <td>38.400002</td>\n      <td>39.160000</td>\n      <td>22401400</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>38.325291</td>\n      <td>38.740002</td>\n      <td>38.830002</td>\n      <td>38.310001</td>\n      <td>38.619999</td>\n      <td>22434000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2094 rows Ã— 6 columns</p>\n</div>\n```\n:::\n:::\n\n\n### With chaining\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npfe_df = (pharma_df\n .iloc[:,1::2] # retrieves only PFE stock data\n .pipe(fix_cols) # Removes the ticker and just shows \n)\npfe_df\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adj Close</th>\n      <th>Close</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>21.793072</td>\n      <td>29.724857</td>\n      <td>30.151802</td>\n      <td>29.620493</td>\n      <td>29.667933</td>\n      <td>16371571</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>21.674822</td>\n      <td>29.563566</td>\n      <td>29.800758</td>\n      <td>29.421251</td>\n      <td>29.743834</td>\n      <td>24786391</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>21.855675</td>\n      <td>29.810247</td>\n      <td>30.227703</td>\n      <td>29.525618</td>\n      <td>29.667933</td>\n      <td>29468681</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>22.154793</td>\n      <td>30.218216</td>\n      <td>30.237192</td>\n      <td>29.962049</td>\n      <td>30.094877</td>\n      <td>20248816</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>22.606922</td>\n      <td>30.834915</td>\n      <td>30.967743</td>\n      <td>30.569260</td>\n      <td>30.683111</td>\n      <td>49169522</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-21</th>\n      <td>39.779552</td>\n      <td>40.209999</td>\n      <td>40.299999</td>\n      <td>39.910000</td>\n      <td>40.090000</td>\n      <td>19227100</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>39.482765</td>\n      <td>39.910000</td>\n      <td>40.200001</td>\n      <td>39.709999</td>\n      <td>40.189999</td>\n      <td>17633700</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>38.908978</td>\n      <td>39.330002</td>\n      <td>39.919998</td>\n      <td>39.279999</td>\n      <td>39.750000</td>\n      <td>24492400</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>38.216469</td>\n      <td>38.630001</td>\n      <td>39.189999</td>\n      <td>38.400002</td>\n      <td>39.160000</td>\n      <td>22401400</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>38.325291</td>\n      <td>38.740002</td>\n      <td>38.830002</td>\n      <td>38.310001</td>\n      <td>38.619999</td>\n      <td>22434000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2094 rows Ã— 6 columns</p>\n</div>\n```\n:::\n:::\n\n\nAs you can see this makes an easier reading. We use the `pipe()` to call our `fix_cols`\nfunction. The resulting dataframe has only the outer level column names. \nIndeed, I agree that as more analysis are added, it gets complicated and harder to understand. \nIndeed, the intermediate calculation steps are not shown in the final version \nwhich makes it difficult to visualise the operation instantaneously. \n\n# Plotting\nSince Pandas' plotting functionality is built on top of Matplotlib, we use it easily to\nplot our data.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n(pharma_df\n .iloc[:,1::2] # retrieves only PFE stock data\n .pipe(fix_cols) # Removes the ticker and just shows \n .Close # fetches only the Close column. Dataframe is now a series\n .plot() # date is used at x-axis and the Close column values at y-axis.\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-5-output-2.png){}\n:::\n:::\n\n\nWe can also adjust plot window size using Matplotlib's `figsize` function.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\npfe_vol = (pharma_df\n .iloc[:,1::2] # retrieves only PFE stock data\n .pipe(fix_cols) # Removes the ticker and just shows \n .Volume # fetches only the volume column. Dataframe is now a series\n .plot(figsize=(10,2)) # date is used at x-axis and the volume column values at y-axis.\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\n# Resampling\n\nSince we have date as our row index, we can leverage `.resample()` feature of Pandas to\nconvert our `PFE` raw data into time periods we want to visualise. The `.resample()` takes\nin an argument which is appropriate for the index. In our case it is date. So, it can take\nmonthly(`M`), weekly(`W`), daily(`Y`), quarterly(`Q`) etc. Bi monthly is possible with\n`2M`. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n(pfe_df\n .Close\n .resample('M') # returns resampler object. Looks for an aggregate function.\n .mean() # monthly average\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\nIf we want to aggregate two columns, then we can use `.agg()` function.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n(pfe_df\n .resample('M')\n .agg({'Close': 'max', 'Open': 'first'})\n .loc['jan 2020': 'apr 2023']\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-8-output-2.png){}\n:::\n:::\n\n\n# Candle Stick chart\n\nWith stock data, it is easier to visualise its pattern using a candle stick chart. \nCandle stick plot is not in Pandas. We can write our own plot function using matplotlib.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom matplotlib import dates\nfig, ax = plt.subplots(figsize=(10,5))\ndef plot_candle(df, ax):\n    #wick\n    ax.vlines(x=df.index, ymin=df.Low, ymax=df.High, colors='k', linewidth=1)\n    #red - decrease\n    red = df.query('Close < Open')\n    ax.vlines(x=red.index, ymin=red.Close, ymax=red.Open, colors='r', linewidth=3)\n    #green - increase\n    green = df.query('Close >= Open')\n    ax.vlines(x=green.index, ymin=green.Close, ymax=green.Open, colors='g',linewidth=3) #check this\n    ax.xaxis.set_major_locator(dates.MonthLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b-%y'))\n    ax.xaxis.set_minor_locator(dates.DayLocator())\n    ax.grid(color='grey')\n    return df\n\n\n(pfe_df\n .resample('d')\n .agg({'Close': 'last', 'Open': 'first', 'Low':'min', 'High':'max'})\n .loc['jan 2023': 'apr 2023']\n .pipe(plot_candle,ax)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n      <th>Open</th>\n      <th>Low</th>\n      <th>High</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-01-01</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-01-02</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-01-03</th>\n      <td>51.259998</td>\n      <td>51.009998</td>\n      <td>50.820000</td>\n      <td>51.330002</td>\n    </tr>\n    <tr>\n      <th>2023-01-04</th>\n      <td>50.130001</td>\n      <td>50.290001</td>\n      <td>49.520000</td>\n      <td>50.630001</td>\n    </tr>\n    <tr>\n      <th>2023-01-05</th>\n      <td>49.660000</td>\n      <td>49.730000</td>\n      <td>48.919998</td>\n      <td>49.990002</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-23</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>39.910000</td>\n      <td>40.189999</td>\n      <td>39.709999</td>\n      <td>40.200001</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>39.330002</td>\n      <td>39.750000</td>\n      <td>39.279999</td>\n      <td>39.919998</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>38.630001</td>\n      <td>39.160000</td>\n      <td>38.400002</td>\n      <td>39.189999</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>38.740002</td>\n      <td>38.619999</td>\n      <td>38.310001</td>\n      <td>38.830002</td>\n    </tr>\n  </tbody>\n</table>\n<p>117 rows Ã— 4 columns</p>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-9-output-2.png){}\n:::\n:::\n\n\nWith the chart, we can determine the patterns such as bearish, bullish etc. We can change\n`.loc`for the period we want to see the pattern.\n\n\n# Calculations\nIn this section we learn certain metrics used on financial data.\n\n## Returns\nHow much percentage of return can be expected? \nWith pandas, we can simply use `.pct_change()` function and get the values. Plotting them\nis as simple as shown previously.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n(pfe_df\n .pct_change()\n .Close\n .plot()\n)\n```\n:::\n\n\n![](./images/returns_plot.png)\n\nHistogram can be an option but it doesn't show negative swing. Somewhat appropriate would\nbe to use bar plot.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n(pfe_df\n .pct_change()\n .Close\n .iloc[-100:] #last 100 rows\n .plot.bar()\n)\n```\n:::\n\n\n![](./images/returns_barplot.png)\n\nThis plot shows the negative trends but the X-axis is illegible. We don't know on which\ndate the closing stock prices changed. This is because Pandas converts/groups whatever on the\nx-axis into categorical variables. For example, for categorical variable such as elephants, \ndogs and cats this works but for dates that isn't correct. \n\n\nWhat if we explicitly say the x-axis as `dates`.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(10,4))\n(pfe_df\n .pct_change()\n .Close\n .iloc[-100:]\n .plot.bar(ax=ax)\n)\nax.xaxis.set_major_locator(dates.MonthLocator())\nax.xaxis.set_major_formatter(dates.DateFormatter('%b-%y'))\nax.xaxis.set_minor_locator(dates.DayLocator())\n```\n:::\n\n\n![](./images/returns_barplot_1970.png)\n\n1970?!? Still Pandas converts dates to categorical variables. \n\nThe solution Matt suggests is to use matplotlib. \n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef my_bar(series, ax):\n    ax.bar(series.index, series)\n    ax.xaxis.set_major_locator(dates.MonthLocator())\n    ax.xaxis.set_major_formatter(dates.DateFormatter('%b-%y'))\n    ax.xaxis.set_minor_locator(dates.DayLocator())\n    return series\n\nfig, ax = plt.subplots(figsize=(10,4))\n_ = ( pfe_df\n .pct_change()\n .Close\n .iloc[-100:]\n .pipe(my_bar, ax)\n)\n```\n:::\n\n\n![](./images/returns_barplot_plt.png)\n\nLooks good now.\n\n## Cumulative returns\n\nCumulative returns shows the investment amount gained or lost over time.\nThe formula is given by\n$$\ncumulative\\_return = \\frac{(current\\_price - original\\_price)}{(curent\\_price)}\n$$\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n(pfe_df\n .Close\n .sub(pfe_df.Close[0])\n .div(pfe_df.Close[0])\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-14-output-2.png){}\n:::\n:::\n\n\nAnother alternate way is to numpy's `cumprod` function. \n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n(pfe_df\n .Close\n .add(1)\n .cumprod()\n .sub(1)\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/dross/miniforge3/envs/mlops/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57: RuntimeWarning:\n\noverflow encountered in accumulate\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-15-output-3.png){}\n:::\n:::\n\n\nAs you can see both plots give the same result.\n\nIf we're to use `.pipe` here, we can do like so:\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndef calc_cumrets(df, col):\n     ser = df[col]\n     return (ser\n             .sub(ser[0])\n             .div(ser[0])\n            )\n(pfe_df\n .pipe(calc_cumrets,'Close')\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-16-output-2.png){}\n:::\n:::\n\n\n### Lambda functions or anonymous functions\nUsing lambda functions we can make impropmtu functions and use it with our chaining.\n\nWe would traditionally call a function like so:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ndef get_returns(df):\n    return calc_cumrets(df, 'Close')\n\nget_returns(pfe_df)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nDate\n2015-01-02    0.000000\n2015-01-05   -0.005426\n2015-01-06    0.002873\n2015-01-07    0.016598\n2015-01-08    0.037344\n                ...   \n2023-04-21    0.352740\n2023-04-24    0.342647\n2023-04-25    0.323135\n2023-04-26    0.299586\n2023-04-27    0.303286\nName: Close, Length: 2094, dtype: float64\n```\n:::\n:::\n\n\nHowever, if we are to use `lambda`, then the above code can be written as:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n(lambda df: get_returns(df))(pfe_df)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nDate\n2015-01-02    0.000000\n2015-01-05   -0.005426\n2015-01-06    0.002873\n2015-01-07    0.016598\n2015-01-08    0.037344\n                ...   \n2023-04-21    0.352740\n2023-04-24    0.342647\n2023-04-25    0.323135\n2023-04-26    0.299586\n2023-04-27    0.303286\nName: Close, Length: 2094, dtype: float64\n```\n:::\n:::\n\n\nNow, with cumulative returns calculation, it would be useful if those values can be assigned to\na new column in the dataframe. It is here that a Pandas feature in `.assign` function is\nhelpful. It helps create new columns. We can couple `.assign` and `lambda` together.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\npfe_df = (pfe_df\n .assign(cum_rets=lambda df:calc_cumrets(df, 'Close'))\n)\n```\n:::\n\n\n## Volatility\nVolatility is a statistical measure of the dispertion of the returns for a given market\nindex in this case stocks. In most cases, higher the volatility, the riskier the stock. It\nis often measured from either standard deviation or variance between returns from that\nstock. Remember `standard deviation` is the measure of deviation of the data relative to\nits mean.\n\nJust like `mean()`, we can calculate `std()`.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n(pfe_df\n .Close\n #.mean()\n .std()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n6.69077286484766\n```\n:::\n:::\n\n\nThe `.assign()` allows consective chaining methods to use\nthese newly created columns. In the below code block, we can use the `pct_change_close`\ncreated in the first line in to the second line. Then, we can calculate 30 day `rolling`\nvolatility. Rolling is nothing but a time frame in which the volatility is calculated. We\ncan see that for the first 15 days the volatility is `NaN`(not a number) and on the 30th\nday, there is an entry.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n(pfe_df\n .assign(pct_change_close=pfe_df.Close.pct_change())\n .pct_change_close\n .rolling(30)\n .std()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nDate\n2015-01-02         NaN\n2015-01-05         NaN\n2015-01-06         NaN\n2015-01-07         NaN\n2015-01-08         NaN\n                ...   \n2023-04-21    0.008945\n2023-04-24    0.009058\n2023-04-25    0.009192\n2023-04-26    0.009718\n2023-04-27    0.009543\nName: pct_change_close, Length: 2094, dtype: float64\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n#rolling volatility\n(pfe_df\n .assign(close_volatility=pfe_df.rolling(30).Close.std(),\n         percent_volatility=pfe_df.Close.pct_change().rolling(30).std())\n .iloc[:,-2:] # fetch only the last two columns\n .plot(subplots=True)\n\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\narray([<AxesSubplot:xlabel='Date'>, <AxesSubplot:xlabel='Date'>],\n      dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-22-output-2.png){}\n:::\n:::\n\n\nWe can also use `.resample` to calculate 15 day volatility as we have `date` as index.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# 15 day volatility\n(pfe_df\n .assign(pct_change_close=pfe_df.Close.pct_change())\n .resample('15D')\n .std()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adj Close</th>\n      <th>Close</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Volume</th>\n      <th>cum_rets</th>\n      <th>pct_change_close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>0.423588</td>\n      <td>0.577756</td>\n      <td>0.554235</td>\n      <td>0.536322</td>\n      <td>0.565220</td>\n      <td>8.716662e+06</td>\n      <td>0.019437</td>\n      <td>0.009335</td>\n    </tr>\n    <tr>\n      <th>2015-01-17</th>\n      <td>0.408931</td>\n      <td>0.557768</td>\n      <td>0.552896</td>\n      <td>0.473576</td>\n      <td>0.428281</td>\n      <td>6.992238e+06</td>\n      <td>0.018764</td>\n      <td>0.011556</td>\n    </tr>\n    <tr>\n      <th>2015-02-01</th>\n      <td>0.864666</td>\n      <td>1.092056</td>\n      <td>1.124398</td>\n      <td>1.137237</td>\n      <td>1.027460</td>\n      <td>1.347935e+07</td>\n      <td>0.036739</td>\n      <td>0.013012</td>\n    </tr>\n    <tr>\n      <th>2015-02-16</th>\n      <td>0.103079</td>\n      <td>0.139368</td>\n      <td>0.153115</td>\n      <td>0.158683</td>\n      <td>0.142704</td>\n      <td>5.436585e+06</td>\n      <td>0.004689</td>\n      <td>0.006524</td>\n    </tr>\n    <tr>\n      <th>2015-03-03</th>\n      <td>0.232107</td>\n      <td>0.313819</td>\n      <td>0.310265</td>\n      <td>0.285296</td>\n      <td>0.329080</td>\n      <td>6.907642e+06</td>\n      <td>0.010557</td>\n      <td>0.008226</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-02-19</th>\n      <td>0.912909</td>\n      <td>0.922787</td>\n      <td>0.942723</td>\n      <td>1.064260</td>\n      <td>1.025597</td>\n      <td>4.710137e+06</td>\n      <td>0.031044</td>\n      <td>0.011505</td>\n    </tr>\n    <tr>\n      <th>2023-03-06</th>\n      <td>0.510382</td>\n      <td>0.515904</td>\n      <td>0.386680</td>\n      <td>0.472090</td>\n      <td>0.610293</td>\n      <td>1.148802e+07</td>\n      <td>0.017356</td>\n      <td>0.011168</td>\n    </tr>\n    <tr>\n      <th>2023-03-21</th>\n      <td>0.414519</td>\n      <td>0.419005</td>\n      <td>0.428108</td>\n      <td>0.305953</td>\n      <td>0.396622</td>\n      <td>3.416600e+06</td>\n      <td>0.014096</td>\n      <td>0.009084</td>\n    </tr>\n    <tr>\n      <th>2023-04-05</th>\n      <td>0.495242</td>\n      <td>0.500601</td>\n      <td>0.483455</td>\n      <td>0.430794</td>\n      <td>0.424291</td>\n      <td>4.807599e+06</td>\n      <td>0.016841</td>\n      <td>0.008860</td>\n    </tr>\n    <tr>\n      <th>2023-04-20</th>\n      <td>0.647205</td>\n      <td>0.654208</td>\n      <td>0.613951</td>\n      <td>0.713320</td>\n      <td>0.629458</td>\n      <td>2.507162e+06</td>\n      <td>0.022009</td>\n      <td>0.010312</td>\n    </tr>\n  </tbody>\n</table>\n<p>203 rows Ã— 8 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# 15 day rolling volatility\n(pfe_df\n .assign(pct_change_close=pfe_df.Close.pct_change())\n .rolling(window=15, min_periods=15)\n .std()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adj Close</th>\n      <th>Close</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Open</th>\n      <th>Volume</th>\n      <th>cum_rets</th>\n      <th>pct_change_close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-21</th>\n      <td>0.591463</td>\n      <td>0.597864</td>\n      <td>0.638385</td>\n      <td>0.562327</td>\n      <td>0.596404</td>\n      <td>3.967966e+06</td>\n      <td>0.020113</td>\n      <td>0.009691</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>0.657297</td>\n      <td>0.664410</td>\n      <td>0.695511</td>\n      <td>0.616351</td>\n      <td>0.626652</td>\n      <td>3.915626e+06</td>\n      <td>0.022352</td>\n      <td>0.009383</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>0.771667</td>\n      <td>0.780017</td>\n      <td>0.784388</td>\n      <td>0.725364</td>\n      <td>0.709656</td>\n      <td>4.093416e+06</td>\n      <td>0.026241</td>\n      <td>0.008983</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>0.957201</td>\n      <td>0.967559</td>\n      <td>0.939399</td>\n      <td>0.930587</td>\n      <td>0.843585</td>\n      <td>4.133347e+06</td>\n      <td>0.032551</td>\n      <td>0.009559</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>1.047608</td>\n      <td>1.058944</td>\n      <td>1.047459</td>\n      <td>1.068349</td>\n      <td>1.011878</td>\n      <td>3.287318e+06</td>\n      <td>0.035625</td>\n      <td>0.008130</td>\n    </tr>\n  </tbody>\n</table>\n<p>2094 rows Ã— 8 columns</p>\n</div>\n```\n:::\n:::\n\n\nWhat happens if the assinged new column name is same as the pandas function name and we\nhave to use further for our analysis? We can include that 'assigned' column within\n`[]`(square) braces and use it. In the below example, we can see how `pct_change`\nconflicts with pandas and is therefore must be put inside `[]` to access it.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# 15 day rolling volatility\n(pfe_df\n .assign(pct_change=pfe_df.Close.pct_change())\n .rolling(window=15, min_periods=15)\n .std()\n #.pct_change\n [\"pct_change\"]\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-25-output-2.png){}\n:::\n:::\n\n\n## Moving averages or rolling windows\nMoving average(MA) of a stock is calculated to help smooth out the price data by creating a\nconstantly updated average price. It helps to mitigate the impacts of random, short-term\nfluctuations on the prices of the stock over a time period. There are two types of moving\naverages - `simple` which is just the arithmetic mean of the given prices over a specified\nnumber of days and `exponential` which is the weighted average that gives significance to\nthe recent prices than old ones, making it an indicator that is more responsive to new\ninfotmation.\n\nMA is used to identify the tread direction of a stock or to determine its support and\nresistance level as it depends on the past prices. The longer the period for the MA, the\ngreater the lag. A 200-day MA has much greater lag than 20-day MA. The gold standard used\nby investers are 50-day and 200-day MAs. \n\nShorter MA for short-term investment and longer MA for long-term. A rising MA means upward\ntrend and declining means downward trend.\n\n### What is a Golden Cross?\nA golden cross is a chart pattern in which a short-term moving average crosses above a long-term moving average. \nThe golden cross is a bullish breakout pattern formed from a crossover involving a security's short-term moving \naverage such as the 15-day moving average, breaking above its long-term moving average, such as the 50-day moving \naverage. As long-term indicators carry more weight, the golden cross indicates a bull market on the horizon \nand is reinforced by high trading volumes.\n\n### Lag\nThese lags can be calculated in Pandas using `shift` function. `shift(1)` means shift\nindex one place down. `shift(2)` means two places down. For example, \n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n(pfe_df\n .assign(s1=pfe_df.Close.shift(1),\n         s2=pfe_df.Close.shift(2))\n [[\"s1\",\"s2\"]]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>s1</th>\n      <th>s2</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>29.724857</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>29.563566</td>\n      <td>29.724857</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>29.810247</td>\n      <td>29.563566</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>30.218216</td>\n      <td>29.810247</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-21</th>\n      <td>39.849998</td>\n      <td>40.240002</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>40.209999</td>\n      <td>39.849998</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>39.910000</td>\n      <td>40.209999</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>39.330002</td>\n      <td>39.910000</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>38.630001</td>\n      <td>39.330002</td>\n    </tr>\n  </tbody>\n</table>\n<p>2094 rows Ã— 2 columns</p>\n</div>\n```\n:::\n:::\n\n\nthe `Close` value in the first row will be on the second row for `shift(1)` and two rows\ndown for `shift(2)`.\n\n\nNow for simple 3-day moving average, we need to average `Close`, `s1`, and `s2`. We can do\nit manually using a `lambda` and use the `rolling` pandas with `window=3` specified.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n(pfe_df\n .assign(s1=pfe_df.Close.shift(1),\n         s2=pfe_df.Close.shift(2),\n         ma3=lambda df_:df_.loc[:,[\"Close\", \"s1\", \"s2\"]].mean(axis='columns'),\n         ma3_builtin=pfe_df.Close.rolling(3).mean()\n        )\n[[\"s1\",\"s2\",\"ma3\",\"ma3_builtin\"]]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>ma3</th>\n      <th>ma3_builtin</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-02</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.724857</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>29.724857</td>\n      <td>NaN</td>\n      <td>29.644212</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2015-01-06</th>\n      <td>29.563566</td>\n      <td>29.724857</td>\n      <td>29.699557</td>\n      <td>29.699557</td>\n    </tr>\n    <tr>\n      <th>2015-01-07</th>\n      <td>29.810247</td>\n      <td>29.563566</td>\n      <td>29.864010</td>\n      <td>29.864010</td>\n    </tr>\n    <tr>\n      <th>2015-01-08</th>\n      <td>30.218216</td>\n      <td>29.810247</td>\n      <td>30.287793</td>\n      <td>30.287793</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-04-21</th>\n      <td>39.849998</td>\n      <td>40.240002</td>\n      <td>40.100000</td>\n      <td>40.100000</td>\n    </tr>\n    <tr>\n      <th>2023-04-24</th>\n      <td>40.209999</td>\n      <td>39.849998</td>\n      <td>39.989999</td>\n      <td>39.989999</td>\n    </tr>\n    <tr>\n      <th>2023-04-25</th>\n      <td>39.910000</td>\n      <td>40.209999</td>\n      <td>39.816667</td>\n      <td>39.816667</td>\n    </tr>\n    <tr>\n      <th>2023-04-26</th>\n      <td>39.330002</td>\n      <td>39.910000</td>\n      <td>39.290001</td>\n      <td>39.290001</td>\n    </tr>\n    <tr>\n      <th>2023-04-27</th>\n      <td>38.630001</td>\n      <td>39.330002</td>\n      <td>38.900002</td>\n      <td>38.900002</td>\n    </tr>\n  </tbody>\n</table>\n<p>2094 rows Ã— 4 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Plotting MAs\n\nWe are getting comfortable with plotting. We select the columns needed to plotted -\n['Close', 'ma3\\_builtin'] for last 200 rows.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n(pfe_df\n .assign(s1=pfe_df.Close.shift(1),\n         s2=pfe_df.Close.shift(2),\n         ma3=lambda df_:df_.loc[:,[\"Close\", \"s1\", \"s2\"]].mean(axis='columns'),\n         ma3_builtin=pfe_df.Close.rolling(3).mean()\n        )\n [['Close', 'ma3_builtin']]\n .iloc[-200:]\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-28-output-2.png){}\n:::\n:::\n\n\nAs we can see the MA smoothes out the little peaks and troughs.\n\n### Golden Cross\n\nSome experts say if there is a crossover between MA-50 and MA-200, it is an indicator to\nbuy or sell.\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n(pfe_df\n .assign(ma50=pfe_df.Close.rolling(50).mean(),\n         ma200=pfe_df.Close.rolling(200).mean()\n        )\n [[\"Close\",\"ma50\",\"ma200\"]]\n .iloc[-650:]\n .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n<AxesSubplot:xlabel='Date'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](py_for_finance_files/figure-html/cell-29-output-2.png){}\n:::\n:::\n\n\n# Technical analysis\nTechnical analysis studies the price and volumes of the investments. Studying the trends\non prices and volumes give analyst to evaluate and identify trading opportunities.\n\nTechnical analysis tools are used to scrutinize the ways supply and demand for a security \nwill affect changes in price, volume, and implied volatility. Past prices are used to\ndetermine future prices.\n\n## OBV- On-balance Volume\nOBV is one such used for technical analysis. It is a momentum indicator that uses volume\nto predict changes in stock price.\n\n### What Does On-Balance Volume Tell You?\nThe actual value of the OBV is unimportant; concentrate on its direction. (source:\n[fidelity](https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/obv))\n\n- When both price and OBV are making higher peaks and higher troughs, the upward trend is likely to continue.\n\n- When both price and OBV are making lower peaks and lower troughs, the downward trend is likely to continue.\n\n- During a trading range, if the OBV is rising, accumulation may be taking placeâ€”a warning of an upward breakout.\n\n- During a trading range, if the OBV is falling, distribution may be taking placeâ€”a warning of a downward breakout.\n\n- When price continues to make higher peaks and OBV fails to make higher peaks, the upward trend is \nlikely to stall or fail. This is called a negative divergence.\n\n- When price continues to make lower troughs and OBV fails to make lower troughs, the downward trend \nis likely to stall or fail. This is called a positive divergence.\n\n### OBV calculation\nIf today's close is greater than yesterday's close then: \nOBV = Yesterdayâ€™s OBV + Todayâ€™s Volume\n\nIf todayâ€™s close is less than yesterdayâ€™s close then: \nOBV = Yesterdayâ€™s OBV â€“ Todayâ€™s Volume\n\nIf todayâ€™s close is equal to yesterdayâ€™s close then: \nOBV = Yesterdayâ€™s OBV\n\n$$\nOBV = OBV_{prev} + \\begin{cases}\nvolume, \\text{ if close > close}_{prev} \\\\\n0, \\text{ if close = close}_{prev}\\\\\n-volume, \\text{ if close < close}_{prev}\n\\end{cases}\n$$\n\nwhere\n\nOBV = current on-balance volume level\n\nOBV~prev~ = previous on-balance volume level\n\nvolume = Latest trading volume amount\n\n## Accumulation distribution indicator\n\n## RSI - Relative strength index\n\n",
    "supporting": [
      "py_for_finance_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}